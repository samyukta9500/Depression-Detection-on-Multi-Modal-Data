# Depression-Detection-on-Multi-Modal-Data

Thesis on detecting depression using multi-modal data and machine learning techniques

Objective:
To develop an accurate and objective model for diagnosing depression by analyzing audio, text, and video data using machine learning and deep learning approaches.

Motivation:
Traditional depression diagnosis is often subjective and limited. This project explores using behavioral cues (like speech, facial expressions, and written text) for more objective detection.

Dataset Used: 
DAIC-WOZ (a dataset of recorded interviews labeled for depression).

Methodology:
Preprocessing data from three sources: text (transcripts), audio (voice features), and video (facial movements).
Implementing models including:
	• Logistic Regression (basic models).
	• LSTM (Long Short-Term Memory) neural networks for sequence modeling.
	• Multimodal models combining audio, text, and video.

Results:
Best performance achieved with all three modalities combined.
Highest accuracy: 96% with Audio + Video + Text.

Conclusion: 
Multi-modal deep learning models can significantly enhance the accuracy of depression detection, providing a valuable tool for clinical applications.
